{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 18.2 (Windows)', 'creationdate': '2023-09-09T07:52:17-04:00', 'author': 'U.S. Census Bureau', 'keywords': 'acsbr-015', 'moddate': '2023-09-12T14:44:47+01:00', 'title': 'Health Insurance Coverage Status and Type by Geography: 2021 and 2022', 'trapped': '/false', 'source': 'us_census\\\\acsbr-015.pdf', 'total_pages': 18, 'page': 0, 'page_label': '1'}, page_content='Health Insurance Coverage Status and Type \\nby Geography: 2021 and 2022\\nAmerican Community Survey Briefs\\nACSBR-015\\nIssued September 2023\\nDouglas Conway and Breauna Branch\\nINTRODUCTION\\nDemographic shifts as well as economic and govern-\\nment policy changes can affect people’s access to \\nhealth coverage. For example, between 2021 and 2022, \\nthe labor market continued to improve, which may \\nhave affected private coverage in the United States \\nduring that time.1 Public policy changes included \\nthe renewal of the Public Health Emergency, which \\nallowed Medicaid enrollees to remain covered under \\nthe Continuous Enrollment Provision.2 The American \\nRescue Plan (ARP) enhanced Marketplace premium \\nsubsidies for those with incomes above 400 percent \\nof the poverty level as well as for unemployed people.3\\nIn addition to national policies, individual states and \\nthe District of Columbia can affect health insurance \\ncoverage by making Marketplace or Medicaid more')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader=PyPDFDirectoryLoader(\"./us_census\")\n",
    "\n",
    "documents=loader.load()\n",
    "\n",
    "text_splitter=RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "\n",
    "final_documents=text_splitter.split_documents(documents)\n",
    "final_documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\9luis\\AppData\\Local\\Temp\\ipykernel_9420\\1588872652.py:1: LangChainDeprecationWarning: The class `HuggingFaceBgeEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  HF_embeddings=HuggingFaceBgeEmbeddings(\n",
      "c:\\Users\\9luis\\OneDrive\\Desktop\\Langchain\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\9luis\\OneDrive\\Desktop\\Langchain\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\9luis\\.cache\\huggingface\\hub\\models--BAAI--bge-small-en-v1.5. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "HF_embeddings=HuggingFaceBgeEmbeddings(\n",
    "    model_name=\"BAAI/bge-small-en-v1.5\", #senetence-transforers/all-MiniLM-16-v2\n",
    "    model_kwargs={'device':'cpu'},\n",
    "    encode_kwargs={'normalize_embeddings':True},\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(384,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array(HF_embeddings.embed_query(final_documents[0].page_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore=FAISS.from_documents(final_documents[:120], HF_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 U.S. Census Bureau\n",
      "WHAT IS HEALTH INSURANCE COVERAGE?\n",
      "This brief presents state-level estimates of health insurance coverage \n",
      "using data from the American Community Survey (ACS). The  \n",
      "U.S. Census Bureau conducts the ACS throughout the year; the \n",
      "survey asks respondents to report their coverage at the time of \n",
      "interview. The resulting measure of health insurance coverage, \n",
      "therefore, reflects an annual average of current comprehensive \n",
      "health insurance coverage status.* This uninsured rate measures a \n",
      "different concept than the measure based on the Current Population \n",
      "Survey Annual Social and Economic Supplement (CPS ASEC). \n",
      "For reporting purposes, the ACS broadly classifies health insurance \n",
      "coverage as private insurance or public insurance. The ACS defines \n",
      "private health insurance as a plan provided through an employer \n",
      "or a union, coverage purchased directly by an individual from an \n",
      "insurance company or through an exchange (such as healthcare.\n",
      "------------------------------------------------\n",
      "private health insurance as a plan provided through an employer \n",
      "or a union, coverage purchased directly by an individual from an \n",
      "insurance company or through an exchange (such as healthcare.\n",
      "gov), or coverage through TRICARE. Public insurance coverage \n",
      "includes federal programs (such as Medicare, Medicaid, and the \n",
      "Children’s Health Insurance Program or CHIP), individual state \n",
      "health plans, and CHAMPVA (Civilian Health and Medical Program \n",
      "at the Department of Veterans Affairs), as well as care provided \n",
      "by the Department of Veterans Affairs. In the ACS, people are \n",
      "considered insured if they were covered by any of these types \n",
      "of health insurance at time of interview. People are considered \n",
      "uninsured if they were not covered by any of these types of health \n",
      "insurance at time of interview or if they only had coverage through \n",
      "the Indian Health Service (IHS), as IHS coverage is not considered \n",
      "comprehensive.\n"
     ]
    }
   ],
   "source": [
    "query=\"What is Health Insurance Coverage?\"\n",
    "relevant_documents=vectorstore.similarity_search(query)\n",
    "\n",
    "print(relevant_documents[0].page_content)\n",
    "# print(\"------------------------------------------------\")\n",
    "# print(relevant_documents[1].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tags=['FAISS', 'HuggingFaceBgeEmbeddings'] vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000023D3296C980> search_kwargs={'k': 3}\n"
     ]
    }
   ],
   "source": [
    "retriever=vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={'k':3})\n",
    "print(retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "hugginface_token=os.environ['HUGGINGFACEHUB_API_TOKEN']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\9luis\\OneDrive\\Desktop\\Langchain\\venv\\Lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'What is the health insurance coverage?\\nHealth insurance coverage is a type of insurance that pays for medical expenses that are not covered by your primary health insurance. This can include things like doctor visits, prescriptions, and hospital stays. Some health insurance plans may also cover preventive care, such as annual check-ups and screenings.'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.llms import HuggingFaceHub\n",
    "\n",
    "hf = HuggingFaceHub(\n",
    "    # repo_id=\"google/flan-t5-base\",  # Using a smaller model that works with the API\n",
    "    # repo_id=\"microsoft/DialoGPT-medium\",\n",
    "    repo_id=\"tiiuae/falcon-7b-instruct\", #resulted in best output\n",
    "    model_kwargs={\"temperature\":0.1,\"max_length\":500}\n",
    "\n",
    ")\n",
    "query=\"What is the health insurance coverage?\"\n",
    "hf.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "C:\\Users\\9luis\\AppData\\Local\\Temp\\ipykernel_9420\\4223237203.py:19: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n",
      "  hf = HuggingFacePipeline(pipeline=pipe)\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, pipeline\n",
    "\n",
    "# Create the pipeline with the correct model type\n",
    "model_id = \"google/flan-t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_id)\n",
    "# Create the pipeline\n",
    "pipe = pipeline(\n",
    "    \"text2text-generation\",  # Use text2text-generation instead of text-generation\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=300,\n",
    "    temperature=0,\n",
    "    device=\"cpu\"\n",
    ")\n",
    "\n",
    "# Create the LangChain pipeline\n",
    "hf = HuggingFacePipeline(pipeline=pipe)\n",
    "llm = hf\n",
    "# hf = HuggingFacePipeline.from_model_id(\n",
    "#     # model_id=\"tiiuae/falcon-7b-instruct\",\n",
    "#     model=model,\n",
    "#     tokenizer=tokenizer,\n",
    "#     # model_id = \"CohereForAI/c4ai-command-r-v01\",\n",
    "#     # model_id=\"mistralai/Mistral-7B-v0.1\",\n",
    "#     task=\"text-generation\",\n",
    "#     pipeline_kwargs={\"temperature\": 0, \"max_new_tokens\": 300, \"device\": \"cpu\"}\n",
    "\n",
    "# )\n",
    "\n",
    "# llm = hf\n",
    "# llm.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_templates=\"\"\"\n",
    "Use the following pieve of context to answer the questions asked.\n",
    "Please try to provide the answer only based on the context\n",
    "\n",
    "{context}\n",
    "Questions:{question}\n",
    "\n",
    "Helpful Answers:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=PromptTemplate(template=prompt_templates,input_variables=[\"context\",\"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrievalQA=RetrievalQA.from_chain_type(\n",
    "    llm=hf,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\":prompt}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"\"\"\n",
    "DIFFERENCES IN THE UNINSURED RATE BY STATE IN 2022\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (810 > 512). Running this sequence through the model will result in indexing errors\n",
      "c:\\Users\\9luis\\OneDrive\\Desktop\\Langchain\\venv\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:629: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACS\n"
     ]
    }
   ],
   "source": [
    "result = retrievalQA.invoke({\"query\": query})\n",
    "print(result['result'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
